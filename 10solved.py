# -*- coding: utf-8 -*-
"""Copy of Cv project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LmRVpqch97cT4ni94T7CIyphD4IFwtlu
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os

def robust_preprocess(image_path):
    # 1. Read Image
    img = cv2.imread(image_path)
    if img is None:
        # Return None if file not found so the loop can skip it smoothly
        return None, None

    # 2. Grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 3. CLAHE (Contrast Limited Adaptive Histogram Equalization)
    # Fixes the "Black Image" issue by normalizing lighting
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)

    # 4. Gaussian Blur
    # Reduces grain and noise
    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)

    # 5. Adaptive Threshold
    # blockSize=19 handles shadows better than 11
    # C=4 filters out background noise
    thresh = cv2.adaptiveThreshold(
        blurred,
        255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        19,
        2
    )

    # 6. Morphological Close
    # Connects broken lines and smooths pixelated numbers
    kernel = np.ones((3,3), np.uint8)
    processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

    return img, processed

# --- Main Execution Loop ---

# Generate filenames ['01.jpg', '02.jpg', ... '16.jpg']
image_files = [f"{i:02d}.jpg" for i in range(1, 17)]

# Set up a large figure: 8 rows, 4 columns
plt.figure(figsize=(20, 40))

plot_idx = 1

for filename in image_files:
    original, processed = robust_preprocess(filename)

    if original is not None:
        # --- Plot Original ---
        plt.subplot(8, 4, plot_idx)
        plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))
        plt.title(f"Orig: {filename}")
        plt.axis('off')
        plot_idx += 1

        # --- Plot Processed ---
        plt.subplot(8, 4, plot_idx)
        plt.imshow(processed, cmap='gray')
        plt.title(f"Proc: {filename}")
        plt.axis('off')
        plot_idx += 1
    else:
        print(f"Warning: Could not find {filename}")

plt.tight_layout()
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# ==========================================
# 1. SMART CONTOUR FINDER (The "Rubber Band" Logic)
# ==========================================
def find_grid_contour(processed_img, img_area):
    contours, _ = cv2.findContours(processed_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key=cv2.contourArea, reverse=True)

    # --- Attempt 1: Find a perfect square loop ---
    for c in contours:
        area = cv2.contourArea(c)
        # Ignore Image Border (>90%) and Noise (<2%)
        if area > (img_area * 0.90) or area < (img_area * 0.02):
            continue

        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)
        if len(approx) == 4:
            return approx

    # --- Attempt 2: The "Rubber Band" (Convex Hull) ---
    # If the line is dashed/broken (like Image 16), we group the pieces.
    significant_points = []
    for c in contours:
        if cv2.contourArea(c) > (img_area * 0.001) and cv2.contourArea(c) < (img_area * 0.90):
            for point in c:
                significant_points.append(point)

    if len(significant_points) > 0:
        significant_points = np.array(significant_points).reshape(-1, 1, 2)
        hull = cv2.convexHull(significant_points)

        # Try to approximate the Hull into a square
        peri = cv2.arcLength(hull, True)
        approx = cv2.approxPolyDP(hull, 0.02 * peri, True)
        if len(approx) == 4:
            return approx
        else:
            # Fallback: Force a rectangle around the hull
            rect = cv2.minAreaRect(hull)
            box = cv2.boxPoints(rect)
            return np.int32(box).reshape(4, 1, 2)

    return None

def get_sudoku_grid(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img_area = img.shape[0] * img.shape[1]

    # --- STRATEGY A: STANDARD (Works for 15/16 images) ---
    # Simple Blur + Threshold
    blurred = cv2.GaussianBlur(gray, (9, 9), 0)
    thresh_standard = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                            cv2.THRESH_BINARY_INV, 11, 2)

    contour = find_grid_contour(thresh_standard, img_area)

    if contour is not None:
        return contour, "Standard"

    # --- STRATEGY B: DARK FALLBACK (Works for Image 08) ---
    # CLAHE (Brightness) + Dilation (Connect faint lines)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    blurred_dark = cv2.GaussianBlur(enhanced, (5, 5), 0)
    thresh_dark = cv2.adaptiveThreshold(blurred_dark, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                        cv2.THRESH_BINARY_INV, 23, 2)

    # Dilate to force connection on dark/faint lines
    kernel = np.ones((3,3), np.uint8)
    dilated = cv2.dilate(thresh_dark, kernel, iterations=2)

    contour = find_grid_contour(dilated, img_area)

    if contour is not None:
        return contour, "Dark/Fallback"

    return None, "Failed"

# ==========================================
# 3. WARPING HELPERS
# ==========================================
def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect

    # 1. Calculate Width and Height as usual
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))

    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))

    # 2. FORCE SQUARE: Pick the largest side
    # This ensures the output is always 1:1 aspect ratio (e.g. 500x500)
    side = max(maxWidth, maxHeight)

    # 3. Construct the destination points using 'side' for both x and y
    dst = np.array([
        [0, 0],
        [side - 1, 0],
        [side - 1, side - 1],
        [0, side - 1]], dtype="float32")

    # 4. Warp
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (side, side)) # Output size is side x side

    return warped

# ==========================================
# MAIN EXECUTION
# ==========================================
image_files = [f"{i:02d}.jpg" for i in range(1, 17)]

plt.figure(figsize=(20, 40))
plot_idx = 1

print("--- Checking Output Dimensions ---")

for filename in image_files:
    img = cv2.imread(filename)
    if img is None: continue

    # Find the grid using our Two-Stage Logic
    contour, strategy = get_sudoku_grid(img)

    if contour is not None:
        # Success: Warp
        warped = four_point_transform(img, contour.reshape(4, 2))

        # --- CHECK DIMENSIONS HERE ---
        h, w = warped.shape[:2]
        print(f"Image {filename}: Width={w}, Height={h} -> {'SQUARE' if w==h else 'RECTANGLE'}")

        # Show Original
        plt.subplot(8, 4, plot_idx)
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title(f"{filename} ({strategy})")
        plt.axis('off')
        plot_idx += 1

        # Show Warped with Dimensions in Title
        plt.subplot(8, 4, plot_idx)
        plt.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB))
        plt.title(f"Success: {w}x{h}") # <--- Modified Title
        plt.axis('off')
        plot_idx += 1
    else:
        # Fail
        print(f"FAILED: {filename}")
        plt.subplot(8, 4, plot_idx); plt.title("FAILED"); plt.axis('off'); plot_idx += 2

plt.tight_layout()
plt.show()

def extract_cells_from_grid(warped_img, grid_size=9):
    """
    Extracts individual cells from the warped Sudoku grid.
    Returns a 9x9 array of cell images.

    Uses a dynamic margin (percentage of cell size) to cut away grid lines
    while keeping the digit, which is usually more central.
    """
    height, width = warped_img.shape[:2]
    cell_height = height // grid_size
    cell_width = width // grid_size

    # Dynamic margins: ~8% of cell size
    margin_y = max(2, int(0.08 * cell_height))
    margin_x = max(2, int(0.08 * cell_width))

    cells = []

    for row in range(grid_size):
        row_cells = []
        for col in range(grid_size):
            y1 = row * cell_height + margin_y
            y2 = (row + 1) * cell_height - margin_y
            x1 = col * cell_width + margin_x
            x2 = (col + 1) * cell_width - margin_x

            # Safety clamp
            y1 = max(0, min(y1, height - 1))
            y2 = max(0, min(y2, height))
            x1 = max(0, min(x1, width - 1))
            x2 = max(0, min(x2, width))

            cell = warped_img[y1:y2, x1:x2]
            row_cells.append(cell)

        cells.append(row_cells)

    return np.array(cells)


def preprocess_cell(cell):
    """
    Preprocesses a single cell for digit recognition.
    Uses adaptive thresholding to handle uneven lighting.
    """
    # Convert to grayscale if needed
    if len(cell.shape) == 3:
        cell = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)

    # Apply slight Gaussian blur to reduce noise
    blurred = cv2.GaussianBlur(cell, (3, 3), 0)

    # Use ADAPTIVE threshold instead of OTSU
    # This handles uneven lighting much better
    thresh = cv2.adaptiveThreshold(
        blurred,
        255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        11,  # Block size - must be odd
        2    # Constant subtracted from mean
    )

    # Remove small noise with morphological opening
    kernel = np.ones((2,2), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)

    return cleaned

    def white_ratio(img):
        return float(np.sum(img == 255)) / img.size

    r_otsu = white_ratio(th_otsu)
    r_adapt = white_ratio(th_adapt)

    # Target: some white, but not full snow
    candidates = []
    if 0.02 < r_otsu < 0.35:
        candidates.append((th_otsu, abs(r_otsu - 0.15)))
    if 0.02 < r_adapt < 0.35:
        candidates.append((th_adapt, abs(r_adapt - 0.15)))

    if candidates:
        thresh = min(candidates, key=lambda x: x[1])[0]
    else:
        # Fallback: choose closer to target ratio
        thresh = th_otsu if abs(r_otsu - 0.15) < abs(r_adapt - 0.15) else th_adapt

    # 5) Morphology to clean and thicken digits
    kernel = np.ones((2, 2), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)
    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel, iterations=1)

    # 6) Remove tiny components (pepper noise)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(cleaned, connectivity=8)
    min_area = 0.002 * cleaned.size  # 0.2% of cell area

    mask = np.zeros_like(cleaned)
    for i in range(1, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        if area >= min_area:
            mask[labels == i] = 255

    return mask


def is_cell_empty(cell, threshold_area_ratio=0.01):
    """
    Determines if a cell is empty using connected components.

    Any connected component covering >= threshold_area_ratio of the cell area
    is considered a real mark (digit). Otherwise the cell is treated as empty.
    """
    # Assume cell is already binary (0 / 255)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(cell, connectivity=8)
    cell_area = cell.size

    for i in range(1, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        if area / float(cell_area) >= threshold_area_ratio:
            return False  # not empty

    return True  # empty


print("Cell extraction + preprocessing functions ready!")

image_files = [f"{i:02d}.jpg" for i in range(1, 17)]

for filename in image_files:
    img = cv2.imread(filename)
    if img is None:
        print(f"Skipping {filename} - file not found")
        continue

    # Get warped grid
    contour, strategy = get_sudoku_grid(img)
    if contour is None:
        print(f"Skipping {filename} - grid detection failed")
        continue

    warped = four_point_transform(img, contour.reshape(4, 2))

    # Extract all 81 cells
    cells = extract_cells_from_grid(warped)

    # Create figure with 2 large subgrids: BEFORE and AFTER
    fig = plt.figure(figsize=(20, 10))
    fig.suptitle(f'{filename} - All 81 Cells: BEFORE vs AFTER preprocess_cell()',
                 fontsize=16, fontweight='bold')

    # LEFT SIDE: Original cells (9x9 grid)
    for row in range(9):
        for col in range(9):
            cell = cells[row, col]

            # Plot original cell
            ax = plt.subplot(9, 18, row * 18 + col + 1)
            ax.imshow(cv2.cvtColor(cell, cv2.COLOR_BGR2RGB))
            ax.axis('off')

            # Add row/col labels on edges
            if col == 0:
                ax.set_ylabel(f'R{row}', fontsize=8, rotation=0, labelpad=15)
            if row == 0:
                ax.set_title(f'C{col}', fontsize=8)

    # RIGHT SIDE: Preprocessed cells (9x9 grid)
    for row in range(9):
        for col in range(9):
            cell = cells[row, col]
            processed = preprocess_cell(cell)

            # Plot preprocessed cell
            ax = plt.subplot(9, 18, row * 18 + col + 10)
            ax.imshow(processed, cmap='gray')
            ax.axis('off')

            # Add row/col labels on edges
            if col == 0:
                ax.set_ylabel(f'R{row}', fontsize=8, rotation=0, labelpad=15)
            if row == 0:
                ax.set_title(f'C{col}', fontsize=8)

    # Add section labels
    fig.text(0.25, 0.98, 'BEFORE (Original)', ha='center', fontsize=14, fontweight='bold')
    fig.text(0.75, 0.98, 'AFTER (Preprocessed)', ha='center', fontsize=14, fontweight='bold')

    plt.tight_layout(rect=[0, 0, 1, 0.97])
    plt.show()

    print(f"✓ Processed {filename}")

print("\n" + "="*80)
print("ALL IMAGES PROCESSED!")
print("="*80)

# ==========================================
# DEBUG is_cell_empty() ON ALL 81 CELLS
# ==========================================

image_files = [f"{i:02d}.jpg" for i in range(1, 17)]

for filename in image_files:
    img = cv2.imread(filename)
    if img is None:
        print(f"Skipping {filename} - file not found")
        continue

    # Get warped grid
    contour, strategy = get_sudoku_grid(img)
    if contour is None:
        print(f"Skipping {filename} - grid detection failed")
        continue

    warped = four_point_transform(img, contour.reshape(4, 2))

    # Extract all 81 cells
    cells = extract_cells_from_grid(warped)

    # Create figure showing empty vs filled classification
    fig = plt.figure(figsize=(22, 11))
    fig.suptitle(f'{filename} - Empty Detection: GREEN=Empty, RED=Has Digit',
                 fontsize=16, fontweight='bold')

    # Statistics
    empty_count = 0
    filled_count = 0

    # Show all 81 cells with color-coded borders
    for row in range(9):
        for col in range(9):
            cell = cells[row, col]
            processed = preprocess_cell(cell)

            # Check if empty
            is_empty = is_cell_empty(processed)
            white_ratio = np.sum(processed == 255) / (processed.shape[0] * processed.shape[1])

            if is_empty:
                empty_count += 1
            else:
                filled_count += 1

            # Plot cell
            ax = plt.subplot(9, 9, row * 9 + col + 1)
            ax.imshow(processed, cmap='gray')

            # Color-coded border and title
            if is_empty:
                # GREEN border for empty
                for spine in ax.spines.values():
                    spine.set_edgecolor('green')
                    spine.set_linewidth(3)
                ax.set_title(f'{white_ratio:.3f}', fontsize=8, color='green')
            else:
                # RED border for filled
                for spine in ax.spines.values():
                    spine.set_edgecolor('red')
                    spine.set_linewidth(3)
                ax.set_title(f'{white_ratio:.3f}', fontsize=8, color='red')

            ax.axis('off')

    # Add summary text
    fig.text(0.5, 0.02,
             f'Empty: {empty_count} cells (GREEN) | Filled: {filled_count} cells (RED) | Threshold: 0.05',
             ha='center', fontsize=12, fontweight='bold',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout(rect=[0, 0.03, 1, 0.98])
    plt.show()

    # Print detailed statistics
    print(f"\n{'='*70}")
    print(f"IMAGE: {filename}")
    print(f"{'='*70}")
    print(f"Empty cells: {empty_count} | Filled cells: {filled_count}")

    # Print grid showing which cells are classified as filled
    print("\nGrid map (0=Empty, 1=Filled):")
    for row in range(9):
        row_str = ""
        for col in range(9):
            cell = cells[row, col]
            processed = preprocess_cell(cell)
            is_empty = is_cell_empty(processed)
            row_str += "0 " if is_empty else "1 "
        print(f"Row {row}: {row_str}")

print("\n" + "="*80)
print("ALL IMAGES DEBUGGED!")
print("="*80)

def extract_digit_from_cell(cell):
    """
    Extracts the digit from a cell by finding the largest contour
    and cropping/centering it.
    IMPROVED: Handles very thin digits like 1 with better detection logic
    """
    if is_cell_empty(cell):
        return None

    # Find contours
    contours, _ = cv2.findContours(cell, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if len(contours) == 0:
        return None

    # Find the largest contour (should be the digit)
    largest_contour = max(contours, key=cv2.contourArea)
    contour_area = cv2.contourArea(largest_contour)

    # Get bounding box
    x, y, w, h = cv2.boundingRect(largest_contour)

    # Calculate cell dimensions for relative comparisons
    cell_height, cell_width = cell.shape
    cell_area = cell_height * cell_width

    # More lenient filtering for noise
    # Key fix: Use area ratio instead of just pixel dimensions
    area_ratio = contour_area / cell_area

    # Must occupy at least 1% of cell area (catches even thin "1"s)
    if area_ratio < 0.01:
        return None

    # Minimum absolute size check (very lenient now)
    if w < 2 or h < 8:  # Height check is more important than width
        return None

    # Maximum size check (avoid selecting entire cell as noise)
    if w > cell_width * 0.95 or h > cell_height * 0.95:
        return None

    # Aspect ratio check - MUCH more lenient for thin digits
    aspect_ratio = h / w

    # Allow very tall thin digits (like 1) but reject horizontal noise
    # Digits should be taller than wide (aspect > 1.0)
    # But can be VERY tall (up to 10:1 for thin "1"s)
    if aspect_ratio < 1.0 or aspect_ratio > 10.0:
        return None

    # Additional check: digit should be reasonably centered
    # This helps reject edge noise
    x_center = x + w / 2
    y_center = y + h / 2
    cell_x_center = cell_width / 2
    cell_y_center = cell_height / 2

    # Allow digit to be within 40% of cell from center
    max_offset_x = cell_width * 0.4
    max_offset_y = cell_height * 0.4

    if (abs(x_center - cell_x_center) > max_offset_x or
        abs(y_center - cell_y_center) > max_offset_y):
        return None

    # Extract digit with some margin
    margin = 2
    x_start = max(0, x - margin)
    y_start = max(0, y - margin)
    x_end = min(cell_width, x + w + margin)
    y_end = min(cell_height, y + h + margin)

    digit = cell[y_start:y_end, x_start:x_end]

    # Resize to standard size (28x28) with padding
    target_size = 28

    # Add padding to make it square while maintaining aspect ratio
    digit_h, digit_w = digit.shape

    if digit_h > digit_w:
        # Height is larger (common for all digits, especially 1)
        # Calculate padding needed to make square
        diff = digit_h - digit_w
        pad_left = diff // 2
        pad_right = diff - pad_left

        # For very thin digits like 1, add extra padding
        if digit_w < digit_h * 0.3:  # Very thin digit
            extra_pad = int(digit_h * 0.15)  # Add 15% extra
            pad_left += extra_pad
            pad_right += extra_pad

        digit = cv2.copyMakeBorder(digit, 0, 0, pad_left, pad_right,
                                   cv2.BORDER_CONSTANT, value=0)
    else:
        # Width is larger (rare for normal digits)
        diff = digit_w - digit_h
        pad_top = diff // 2
        pad_bottom = diff - pad_top
        digit = cv2.copyMakeBorder(digit, pad_top, pad_bottom, 0, 0,
                                   cv2.BORDER_CONSTANT, value=0)

    # Resize to target size
    digit_resized = cv2.resize(digit, (target_size, target_size),
                               interpolation=cv2.INTER_AREA)

    # Add small border for better matching
    digit_final = cv2.copyMakeBorder(digit_resized, 2, 2, 2, 2,
                                     cv2.BORDER_CONSTANT, value=0)

    return digit_final

print("✓ Digit extraction functions ready!")
print("✓ IMPROVED digit detection:")
print("  - Uses area ratio (1% minimum) instead of fixed width")
print("  - Max aspect ratio: 10:1 (handles very thin '1's)")
print("  - Minimum height: 8 pixels (more important than width)")
print("  - Checks digit centering to reject edge noise")
print("  - Extra padding for digits thinner than 30% of height")

# ==========================================
# DEBUG extract_digit_from_cell() ON ALL CELLS
# ==========================================

image_files = [f"{i:02d}.jpg" for i in range(1, 17)]

for filename in image_files:
    img = cv2.imread(filename)
    if img is None:
        print(f"Skipping {filename} - file not found")
        continue

    # Get warped grid
    contour, strategy = get_sudoku_grid(img)
    if contour is None:
        print(f"Skipping {filename} - grid detection failed")
        continue

    warped = four_point_transform(img, contour.reshape(4, 2))

    # Extract all 81 cells
    cells = extract_cells_from_grid(warped)

    # Create figure showing digit extraction results
    fig = plt.figure(figsize=(24, 11))
    fig.suptitle(f'{filename} - Digit Extraction Debug',
                 fontsize=16, fontweight='bold')

    # Statistics
    empty_count = 0
    extracted_count = 0
    failed_count = 0

    print(f"\n{'='*80}")
    print(f"IMAGE: {filename}")
    print(f"{'='*80}")

    # Show all 81 cells: Original Preprocessed | Extracted Digit
    for row in range(9):
        for col in range(9):
            cell = cells[row, col]
            processed = preprocess_cell(cell)

            # Try to extract digit
            extracted = extract_digit_from_cell(processed)

            # Determine status
            if is_cell_empty(processed):
                status = "EMPTY"
                color = "green"
                empty_count += 1
            elif extracted is not None:
                status = "EXTRACTED"
                color = "blue"
                extracted_count += 1
            else:
                status = "FAILED"
                color = "red"
                failed_count += 1

            # Calculate position for 3-column layout
            base_col = col * 3

            # Column 1: Preprocessed cell
            ax1 = plt.subplot(9, 27, row * 27 + base_col + 1)
            ax1.imshow(processed, cmap='gray')
            ax1.axis('off')
            if row == 0:
                ax1.set_title(f'C{col}\nPrep', fontsize=7)

            # Column 2: Extracted digit or status
            ax2 = plt.subplot(9, 27, row * 27 + base_col + 2)
            if extracted is not None:
                ax2.imshow(extracted, cmap='gray')
                ax2.set_title('✓', fontsize=10, color=color, fontweight='bold')
            else:
                ax2.text(0.5, 0.5, status, ha='center', va='center',
                        fontsize=6, color=color, fontweight='bold',
                        transform=ax2.transAxes)
                ax2.set_title('✗', fontsize=10, color=color, fontweight='bold')
            ax2.axis('off')

            # Column 3: Size info or empty space
            ax3 = plt.subplot(9, 27, row * 27 + base_col + 3)
            if extracted is not None:
                h, w = extracted.shape
                ax3.text(0.5, 0.5, f'{w}x{h}', ha='center', va='center',
                        fontsize=6, transform=ax3.transAxes)
            ax3.axis('off')

            # Print detailed info for non-empty cells
            if not is_cell_empty(processed):
                contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if len(contours) > 0:
                    largest = max(contours, key=cv2.contourArea)
                    x, y, w, h = cv2.boundingRect(largest)
                    aspect = h / w if w > 0 else 0
                    print(f"  [{row},{col}] Status={status:10s} | Contours={len(contours)} | "
                          f"BBox=({w}x{h}) | Aspect={aspect:.2f}")
                else:
                    print(f"  [{row},{col}] Status={status:10s} | No contours found")

    # Add summary
    fig.text(0.5, 0.02,
             f'Empty: {empty_count} | Extracted: {extracted_count} | Failed: {failed_count}',
             ha='center', fontsize=12, fontweight='bold',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout(rect=[0, 0.03, 1, 0.98])
    plt.show()

    print(f"\nSummary: Empty={empty_count}, Extracted={extracted_count}, Failed={failed_count}")

print("\n" + "="*80)
print("ALL IMAGES DEBUGGED!")
print("="*80)

# ==========================================
# STEP 1: CREATE MULTIPLE TEMPLATES PER DIGIT
# ==========================================

def create_multiple_templates_per_digit():
    """
    Create multiple template variations for each digit (1-9).
    Each digit gets 6 different variations to handle different styles and thicknesses.
    """
    templates = {}

    for digit in range(1, 10):
        digit_templates = []

        # Variation 1: Thin SIMPLEX (thickness=1)
        img1 = np.zeros((32, 32), dtype=np.uint8)
        text_size = cv2.getTextSize(str(digit), cv2.FONT_HERSHEY_SIMPLEX, 1.0, 1)[0]
        text_x = (32 - text_size[0]) // 2
        text_y = (32 + text_size[1]) // 2
        cv2.putText(img1, str(digit), (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, 255, 1, cv2.LINE_AA)
        digit_templates.append(img1)

        # Variation 2: Medium SIMPLEX (thickness=2)
        img2 = np.zeros((32, 32), dtype=np.uint8)
        cv2.putText(img2, str(digit), (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, 255, 2, cv2.LINE_AA)
        digit_templates.append(img2)

        # Variation 3: Bold SIMPLEX (thickness=3)
        img3 = np.zeros((32, 32), dtype=np.uint8)
        cv2.putText(img3, str(digit), (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, 255, 3, cv2.LINE_AA)
        digit_templates.append(img3)

        # Variation 4: Thin DUPLEX (thickness=1)
        img4 = np.zeros((32, 32), dtype=np.uint8)
        text_size4 = cv2.getTextSize(str(digit), cv2.FONT_HERSHEY_DUPLEX, 0.9, 1)[0]
        text_x4 = (32 - text_size4[0]) // 2
        text_y4 = (32 + text_size4[1]) // 2
        cv2.putText(img4, str(digit), (text_x4, text_y4), cv2.FONT_HERSHEY_DUPLEX, 0.9, 255, 1, cv2.LINE_AA)
        digit_templates.append(img4)

        # Variation 5: Medium DUPLEX (thickness=2)
        img5 = np.zeros((32, 32), dtype=np.uint8)
        cv2.putText(img5, str(digit), (text_x4, text_y4), cv2.FONT_HERSHEY_DUPLEX, 0.9, 255, 2, cv2.LINE_AA)
        digit_templates.append(img5)

        # Variation 6: Bold DUPLEX (thickness=3)
        img6 = np.zeros((32, 32), dtype=np.uint8)
        cv2.putText(img6, str(digit), (text_x4, text_y4), cv2.FONT_HERSHEY_DUPLEX, 0.9, 255, 3, cv2.LINE_AA)
        digit_templates.append(img6)

        templates[digit] = digit_templates

    return templates

# Create the templates
multi_templates = create_multiple_templates_per_digit()

# Visualize all templates
print("="*80)
print("MULTIPLE TEMPLATES PER DIGIT")
print("="*80)

fig, axes = plt.subplots(9, 6, figsize=(18, 24))
fig.suptitle("Multiple Template Variations per Digit (6 variations each)", fontsize=16, fontweight='bold')

for digit in range(1, 10):
    templates_list = multi_templates[digit]
    for var_idx, template in enumerate(templates_list):
        ax = axes[digit-1, var_idx]
        ax.imshow(template, cmap='gray')
        if var_idx == 0:
            ax.set_ylabel(f'Digit {digit}', fontsize=12, fontweight='bold')
        if digit == 1:
            variation_names = ['Thin\nSIMPLEX', 'Med\nSIMPLEX', 'Bold\nSIMPLEX',
                             'Thin\nDUPLEX', 'Med\nDUPLEX', 'Bold\nDUPLEX']
            ax.set_title(variation_names[var_idx], fontsize=9)
        ax.axis('off')

plt.tight_layout()
plt.show()

print("✓ Created 6 template variations for each digit (1-9)")
print("✓ Total templates: 54")

def match_digit_with_contour_analysis(digit_img, templates):
    """
    Enhanced digit matching using contour shape analysis + template matching.
    Always returns the best match (never rejects based on gap).
    """
    if digit_img is None:
        return 0, 0.0, {}

    # Normalize the digit
    digit_normalized = cv2.normalize(digit_img, None, 0, 255, cv2.NORM_MINMAX)

    # Prepare variations of the input digit
    kernel = np.ones((2,2), np.uint8)
    digit_thinned = cv2.erode(digit_normalized, kernel, iterations=1)
    digit_thickened = cv2.dilate(digit_normalized, kernel, iterations=1)

    input_variations = [digit_normalized, digit_thinned, digit_thickened]

    # ==========================================
    # EXTRACT CONTOUR FEATURES FROM INPUT DIGIT
    # ==========================================
    input_contours, _ = cv2.findContours(digit_normalized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    input_contour_features = {}
    if len(input_contours) > 0:
        # Get the largest contour (main digit shape) - FIXED
        main_contour = max(input_contours, key=cv2.contourArea)

        # Feature 1: Contour area ratio
        input_contour_features['area_ratio'] = cv2.contourArea(main_contour) / (digit_normalized.shape[0] * digit_normalized.shape[1])

        # Feature 2: Perimeter
        input_contour_features['perimeter'] = cv2.arcLength(main_contour, True)

        # Feature 3: Bounding box aspect ratio
        x, y, w, h = cv2.boundingRect(main_contour)
        input_contour_features['aspect_ratio'] = h / w if w > 0 else 0

        # Feature 4: Extent (ratio of contour area to bounding box area)
        input_contour_features['extent'] = cv2.contourArea(main_contour) / (w * h) if (w * h) > 0 else 0

        # Feature 5: Solidity (ratio of contour area to convex hull area)
        hull = cv2.convexHull(main_contour)
        hull_area = cv2.contourArea(hull)
        input_contour_features['solidity'] = cv2.contourArea(main_contour) / hull_area if hull_area > 0 else 0

        # Feature 6: Number of contours (holes detection - important for 6, 8, 9, 0)
        all_contours, _ = cv2.findContours(digit_normalized, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
        input_contour_features['num_contours'] = len(all_contours)

        # Feature 7: Hu Moments (shape descriptors - rotation invariant)
        moments = cv2.moments(main_contour)
        hu_moments = cv2.HuMoments(moments).flatten()
        input_contour_features['hu_moments'] = hu_moments
    else:
        # Default features if no contour found
        input_contour_features = {
            'area_ratio': 0, 'perimeter': 0, 'aspect_ratio': 0,
            'extent': 0, 'solidity': 0, 'num_contours': 0,
            'hu_moments': np.zeros(7)
        }

    # Store comprehensive scores for debugging
    debug_info = {'input_contour_features': input_contour_features}

    # Collect multiple metrics for each digit
    digit_scores = {}

    for digit_val in range(1, 10):
        template_list = templates[digit_val]

        # Metrics storage
        ccoeff_scores = []
        ccorr_scores = []
        sqdiff_scores = []
        contour_similarity_scores = []

        # Test each input variation against each template variation
        for input_var in input_variations:
            for template in template_list:

                # Resize input to match template
                if input_var.shape != template.shape:
                    input_resized = cv2.resize(input_var, template.shape[::-1])
                else:
                    input_resized = input_var

                # METRIC 1: Correlation Coefficient
                result_ccoeff = cv2.matchTemplate(input_resized, template, cv2.TM_CCOEFF_NORMED)
                _, max_ccoeff, _, _ = cv2.minMaxLoc(result_ccoeff)
                ccoeff_scores.append(max_ccoeff)

                # METRIC 2: Cross-Correlation
                result_ccorr = cv2.matchTemplate(input_resized, template, cv2.TM_CCORR_NORMED)
                _, max_ccorr, _, _ = cv2.minMaxLoc(result_ccorr)
                ccorr_scores.append(max_ccorr)

                # METRIC 3: Squared Difference (inverted)
                result_sqdiff = cv2.matchTemplate(input_resized, template, cv2.TM_SQDIFF_NORMED)
                min_sqdiff, _, _, _ = cv2.minMaxLoc(result_sqdiff)
                sqdiff_scores.append(1.0 - min_sqdiff)

                # METRIC 4: CONTOUR SHAPE SIMILARITY
                # Extract contours from template
                template_contours, _ = cv2.findContours(template, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

                if len(template_contours) > 0 and len(input_contours) > 0:
                    template_main = max(template_contours, key=cv2.contourArea)

                    # Calculate template features
                    tx, ty, tw, th = cv2.boundingRect(template_main)
                    template_aspect = th / tw if tw > 0 else 0
                    template_extent = cv2.contourArea(template_main) / (tw * th) if (tw * th) > 0 else 0

                    template_hull = cv2.convexHull(template_main)
                    template_hull_area = cv2.contourArea(template_hull)
                    template_solidity = cv2.contourArea(template_main) / template_hull_area if template_hull_area > 0 else 0

                    template_all_contours, _ = cv2.findContours(template, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                    template_num_contours = len(template_all_contours)

                    # Calculate Hu Moments for template
                    template_moments = cv2.moments(template_main)
                    template_hu = cv2.HuMoments(template_moments).flatten()

                    # Compare features
                    aspect_diff = abs(input_contour_features['aspect_ratio'] - template_aspect)
                    extent_diff = abs(input_contour_features['extent'] - template_extent)
                    solidity_diff = abs(input_contour_features['solidity'] - template_solidity)
                    contour_count_match = 1.0 if input_contour_features['num_contours'] == template_num_contours else 0.5

                    # Hu Moments similarity (use first 3 moments, they're most reliable)
                    hu_similarity = 0
                    for i in range(3):
                        if template_hu[i] != 0:
                            hu_similarity += 1.0 / (1.0 + abs(np.log10(abs(input_contour_features['hu_moments'][i])) -
                                                              np.log10(abs(template_hu[i]))))
                    hu_similarity /= 3.0

                    # Combined contour similarity score
                    contour_score = (
                        (1.0 - min(aspect_diff, 1.0)) * 0.25 +  # Aspect ratio match
                        (1.0 - min(extent_diff, 1.0)) * 0.20 +  # Extent match
                        (1.0 - min(solidity_diff, 1.0)) * 0.20 +  # Solidity match
                        contour_count_match * 0.15 +  # Number of contours (holes)
                        hu_similarity * 0.20  # Shape moments
                    )

                    contour_similarity_scores.append(contour_score)
                else:
                    contour_similarity_scores.append(0.0)

                # Try with small rotations for CCOEFF
                for angle in [-3, 3]:
                    M = cv2.getRotationMatrix2D((16, 16), angle, 1.0)
                    rotated = cv2.warpAffine(input_resized, M, (32, 32))
                    result_rot = cv2.matchTemplate(rotated, template, cv2.TM_CCOEFF_NORMED)
                    _, max_val_rot, _, _ = cv2.minMaxLoc(result_rot)
                    ccoeff_scores.append(max_val_rot)

        # Calculate statistics for each metric
        max_ccoeff = max(ccoeff_scores) if ccoeff_scores else 0
        avg_ccoeff_top3 = np.mean(sorted(ccoeff_scores, reverse=True)[:3]) if len(ccoeff_scores) >= 3 else np.mean(ccoeff_scores)

        max_ccorr = max(ccorr_scores) if ccorr_scores else 0
        max_sqdiff = max(sqdiff_scores) if sqdiff_scores else 0

        max_contour = max(contour_similarity_scores) if contour_similarity_scores else 0
        avg_contour_top3 = np.mean(sorted(contour_similarity_scores, reverse=True)[:3]) if len(contour_similarity_scores) >= 3 else np.mean(contour_similarity_scores)

        # COMBINED SCORE with CONTOUR ANALYSIS (increased weight)
        combined_score = (
            0.35 * max_ccoeff +           # Max correlation coefficient (35%)
            0.15 * avg_ccoeff_top3 +      # Average of top 3 CCOEFF (15%)
            0.10 * max_ccorr +            # Max cross-correlation (10%)
            0.10 * max_sqdiff +           # Max inverted squared diff (10%)
            0.20 * max_contour +          # Max contour similarity (20%)
            0.10 * avg_contour_top3       # Average contour similarity (10%)
        )

        digit_scores[digit_val] = {
            'combined': combined_score,
            'max_ccoeff': max_ccoeff,
            'avg_ccoeff_top3': avg_ccoeff_top3,
            'max_ccorr': max_ccorr,
            'max_sqdiff': max_sqdiff,
            'max_contour': max_contour,
            'avg_contour_top3': avg_contour_top3,
            'all_ccoeff': ccoeff_scores,
            'all_ccorr': ccorr_scores,
            'all_sqdiff': sqdiff_scores,
            'all_contour': contour_similarity_scores
        }

    # Find best match based on combined score
    best_match = max(digit_scores.items(), key=lambda x: x[1]['combined'])
    best_digit = best_match[0]
    best_score = best_match[1]['combined']

    # Get sorted list for confidence analysis
    sorted_by_combined = sorted(digit_scores.items(), key=lambda x: x[1]['combined'], reverse=True)

    # Calculate confidence metrics
    first_score = sorted_by_combined[0][1]['combined']
    second_score = sorted_by_combined[1][1]['combined'] if len(sorted_by_combined) > 1 else 0
    score_gap = first_score - second_score

    # Store debug info
    debug_info['digit_scores'] = digit_scores
    debug_info['sorted_by_combined'] = sorted_by_combined
    debug_info['score_gap'] = score_gap
    debug_info['first_score'] = first_score
    debug_info['second_score'] = second_score

    # SIMPLE THRESHOLD - Only reject if score is very low
    # ALWAYS return best match if score > threshold (ignore gap)
    if best_score < 0.38:
        return 0, best_score, debug_info

    # SPECIAL CASE: If best digit is 2, check if 1 is close behind
    # CHANGED: Choose 1 instead of 2 if difference is between 0 and 0.1
    if best_digit == 2 or best_digit ==4:
        digit_1_score = digit_scores[1]['combined']
        digit_2_score = best_score
        score_difference = digit_2_score - digit_1_score

        # If 2 is winning but 1 is within 0.1, choose 1 instead
        if 0 <= score_difference <= 0.1:
            print(f"  [CORRECTION] Changed 2→1 (diff={score_difference:.3f}, 1_score={digit_1_score:.3f}, 2_score={digit_2_score:.3f})")
            return 1, digit_1_score, debug_info

    # Otherwise, ALWAYS return the best digit regardless of gap
    return best_digit, best_score, debug_info


print("✓ match_digit_with_contour_analysis() function ready!")
print("✓ UPDATED: Choose 1 over 2 if difference is between 0 and 0.1")

def recognize_sudoku_grid(cells, templates):
    """
    Recognizes all digits in the Sudoku grid with improved matching.
    Returns a 9x9 numpy array with recognized digits (0 for empty cells).
    """
    grid = np.zeros((9, 9), dtype=int)
    confidence_grid = np.zeros((9, 9), dtype=float)

    for row in range(9):
        for col in range(9):
            cell = preprocess_cell(cells[row][col])

            # Check if empty first
            if is_cell_empty(cell):
                grid[row][col] = 0
                confidence_grid[row][col] = 0.0
                continue

            # Extract digit
            digit_img = extract_digit_from_cell(cell)

            if digit_img is not None:
                digit, confidence = match_digit(digit_img, templates)
                grid[row][col] = digit
                confidence_grid[row][col] = confidence
            else:
                grid[row][col] = 0
                confidence_grid[row][col] = 0.0

    return grid, confidence_grid

# ==========================================
# SIMPLE DEBUG VISUALIZATION
# ==========================================

image_files = [f"{i:02d}.jpg" for i in range(1, 17)]

for filename in image_files:
    img = cv2.imread(filename)
    if img is None:
        print(f"Skipping {filename} - file not found")
        continue

    # Get warped grid
    contour, strategy = get_sudoku_grid(img)
    if contour is None:
        print(f"Skipping {filename} - grid detection failed")
        continue

    warped = four_point_transform(img, contour.reshape(4, 2))
    cells = extract_cells_from_grid(warped)

    print(f"\n{'='*80}")
    print(f"IMAGE: {filename}")
    print(f"{'='*80}")

    # Collect all cells with digits
    cells_with_digits = []
    for row in range(9):
        for col in range(9):
            cell = cells[row, col]
            processed = preprocess_cell(cell)

            if not is_cell_empty(processed):
                extracted = extract_digit_from_cell(processed)
                if extracted is not None:
                    cells_with_digits.append((row, col, extracted, processed))

    num_cells = len(cells_with_digits)
    print(f"Found {num_cells} cells with digits to analyze\n")

    if num_cells == 0:
        print("No digits found in this image, skipping visualization")
        continue

    # Calculate grid dimensions - simple 4 column layout
    cols_per_cell = 4  # simple: digit, result, top scores, bar chart
    max_cols = 12  # 3 cells per row
    cells_per_row = max_cols // cols_per_cell
    num_rows = (num_cells + cells_per_row - 1) // cells_per_row

    # Create figure
    fig = plt.figure(figsize=(18, num_rows * 3))
    fig.suptitle(f'{filename} - Digit Recognition Results',
                 fontsize=16, fontweight='bold')

    # Process each cell
    for cell_idx, (row, col, extracted, processed) in enumerate(cells_with_digits):

        # Calculate subplot position
        subplot_row = cell_idx // cells_per_row
        subplot_col = (cell_idx % cells_per_row) * cols_per_cell
        base_idx = subplot_row * max_cols + subplot_col + 1

        # Run matching with contour analysis
        best_match, best_score, debug_info = match_digit_with_contour_analysis(extracted, multi_templates)

        # Extract debug information
        sorted_by_combined = debug_info['sorted_by_combined']
        score_gap = debug_info['score_gap']

        # Print simple results
        top_3 = sorted_by_combined[:3]
        print(f"Cell [{row},{col}]: Chosen={best_match} (score={best_score:.3f}) | "
              f"Top-3: {top_3[0][0]}:{top_3[0][1]['combined']:.3f}, "
              f"{top_3[1][0]}:{top_3[1][1]['combined']:.3f}, "
              f"{top_3[2][0]}:{top_3[2][1]['combined']:.3f} | Gap={score_gap:.3f}")

        # Col 1: Input digit
        ax1 = plt.subplot(num_rows, max_cols, base_idx)
        ax1.imshow(extracted, cmap='gray')
        ax1.set_title(f'[{row},{col}]', fontsize=10, fontweight='bold')
        ax1.axis('off')

        # Col 2: Result (large digit)
        ax2 = plt.subplot(num_rows, max_cols, base_idx + 1)
        if best_match > 0:
            # Color based on score
            if best_score >= 0.60:
                color = 'darkgreen'
            elif best_score >= 0.50:
                color = 'green'
            elif best_score >= 0.38:
                color = 'orange'
            else:
                color = 'red'

            ax2.text(0.5, 0.5, str(best_match), ha='center', va='center',
                    fontsize=40, color=color, fontweight='bold',
                    transform=ax2.transAxes)
            ax2.set_title(f'{best_score:.3f}', fontsize=10, color=color, fontweight='bold')
        else:
            ax2.text(0.5, 0.5, 'X', ha='center', va='center',
                    fontsize=40, color='red', fontweight='bold',
                    transform=ax2.transAxes)
            ax2.set_title('REJECT', fontsize=10, color='red')
        ax2.axis('off')

        # Col 3: Top 5 scores as text
        ax3 = plt.subplot(num_rows, max_cols, base_idx + 2)
        top_5_text = "Top 5:\n"
        for i, (d, scores) in enumerate(sorted_by_combined[:5]):
            marker = "★" if d == best_match else " "
            top_5_text += f"{i+1}.{marker}{d}: {scores['combined']:.3f}\n"
        ax3.text(0.1, 0.5, top_5_text, ha='left', va='center',
                fontsize=9, family='monospace', transform=ax3.transAxes)
        ax3.axis('off')

        # Col 4: Bar chart
        ax4 = plt.subplot(num_rows, max_cols, base_idx + 3)
        top_5 = sorted_by_combined[:5]
        colors_bar = ['darkgreen' if d == best_match else 'lightgray' for d, _ in top_5]
        ax4.barh(range(5), [scores['combined'] for _, scores in top_5],
                  color=colors_bar, height=0.7)
        ax4.set_yticks(range(5))
        ax4.set_yticklabels([str(d) for d, _ in top_5], fontsize=11, fontweight='bold')
        ax4.set_xlim(0, 1)
        ax4.set_xticks([0, 0.38, 0.60, 1])
        ax4.set_xticklabels(['0', '.38', '.60', '1'], fontsize=8)
        ax4.axvline(x=0.38, color='red', linestyle='--', linewidth=1, alpha=0.5)
        ax4.axvline(x=0.60, color='green', linestyle='--', linewidth=1, alpha=0.5)
        ax4.tick_params(labelsize=9)

    plt.tight_layout(rect=[0, 0.02, 1, 0.98])
    plt.show()

    # Run full grid recognition
    print("\n" + "="*80)
    print("FINAL RECOGNIZED SUDOKU GRID:")
    print("="*80)

    grid = np.zeros((9, 9), dtype=int)
    confidence_grid = np.zeros((9, 9), dtype=float)

    for row in range(9):
        for col in range(9):
            cell = cells[row][col]
            processed = preprocess_cell(cell)

            if is_cell_empty(processed):
                continue

            extracted = extract_digit_from_cell(processed)
            if extracted is not None:
                digit, confidence, _ = match_digit_with_contour_analysis(extracted, multi_templates)
                grid[row][col] = digit
                confidence_grid[row][col] = confidence

    # Print the grid
    for row in range(9):
        if row % 3 == 0 and row != 0:
            print("-" * 37)
        row_str = ""
        for col in range(9):
            if col % 3 == 0 and col != 0:
                row_str += "| "
            digit = grid[row, col]
            conf = confidence_grid[row, col]
            if digit > 0:
                if conf >= 0.60:
                    row_str += f"{digit} "
                elif conf >= 0.50:
                    row_str += f"{digit} "
                else:
                    row_str += f"{digit}?"
            else:
                row_str += ". "
        print(row_str)
    print("="*80)

    # Statistics
    total_filled = np.sum(grid > 0)
    high_conf = np.sum(confidence_grid >= 0.60)
    good_conf = np.sum((confidence_grid >= 0.50) & (confidence_grid < 0.60))
    low_conf = np.sum((confidence_grid >= 0.38) & (confidence_grid < 0.50))

    print(f"\nStatistics: Total={total_filled} | High(≥0.60)={high_conf} | "
          f"Good(0.50-0.60)={good_conf} | Low(0.38-0.50)={low_conf}\n")

print("\n" + "="*80)
print("ALL IMAGES PROCESSED!")
print("="*80)

def is_valid(grid, row, col, num):
    """
    Check if placing num at grid[row][col] is valid.
    """
    # Check row
    if num in grid[row]:
        return False

    # Check column
    if num in grid[:, col]:
        return False

    # Check 3x3 box
    box_row, box_col = 3 * (row // 3), 3 * (col // 3)
    box = grid[box_row:box_row+3, box_col:box_col+3]
    if num in box:
        return False

    return True

def solve_sudoku(grid):
    """
    Solves the Sudoku puzzle using backtracking.
    Returns True if solved, False if unsolvable.
    """
    # Find empty cell
    for row in range(9):
        for col in range(9):
            if grid[row][col] == 0:
                # Try digits 1-9
                for num in range(1, 10):
                    if is_valid(grid, row, col, num):
                        grid[row][col] = num

                        if solve_sudoku(grid):
                            return True

                        # Backtrack
                        grid[row][col] = 0

                return False

    return True

def validate_sudoku(grid):
    """
    Validates if the recognized Sudoku grid is reasonable.
    Checks for duplicates in rows, columns, and boxes.
    """
    for i in range(9):
        # Check row
        row = [x for x in grid[i] if x != 0]
        if len(row) != len(set(row)):
            return False, f"Duplicate in row {i+1}"

        # Check column
        col = [x for x in grid[:, i] if x != 0]
        if len(col) != len(set(col)):
            return False, f"Duplicate in column {i+1}"

    # Check 3x3 boxes
    for box_row in range(0, 9, 3):
        for box_col in range(0, 9, 3):
            box = grid[box_row:box_row+3, box_col:box_col+3].flatten()
            box = [x for x in box if x != 0]
            if len(box) != len(set(box)):
                return False, f"Duplicate in box at ({box_row//3+1}, {box_col//3+1})"

    return True, "Valid"

print("Sudoku solver ready!")

def process_sudoku_image_updated(image_path, templates):
    """
    Complete pipeline: Load image -> Extract grid -> Recognize digits -> Solve
    Uses the new match_digit_with_contour_analysis function
    """
    img = cv2.imread(image_path)
    if img is None:
        return None, None, None, "Image not found"

    # Get warped grid
    contour, strategy = get_sudoku_grid(img)

    if contour is None:
        return None, None, None, "Failed to detect grid"

    warped = four_point_transform(img, contour.reshape(4, 2))

    # Extract cells
    cells = extract_cells_from_grid(warped)

    # Recognize digits using NEW function
    grid = np.zeros((9, 9), dtype=int)
    confidence_grid = np.zeros((9, 9), dtype=float)

    for row in range(9):
        for col in range(9):
            cell = cells[row][col]
            processed = preprocess_cell(cell)

            if is_cell_empty(processed):
                continue

            extracted = extract_digit_from_cell(processed)
            if extracted is not None:
                # Use the NEW function here
                digit, confidence, _ = match_digit_with_contour_analysis(extracted, templates)
                grid[row][col] = digit
                confidence_grid[row][col] = confidence

    # Validate
    is_valid_grid, validation_msg = validate_sudoku(grid)

    if not is_valid_grid:
        return grid, None, confidence_grid, f"Invalid grid: {validation_msg}"

    # Solve
    solved_grid = grid.copy()
    if solve_sudoku(solved_grid):
        return grid, solved_grid, confidence_grid, "Success"
    else:
        return grid, None, confidence_grid, "Unsolvable puzzle"

def visualize_results(original_img, recognized_grid, solved_grid, confidence_grid):
    """
    Visualizes the original image, recognized grid, and solved grid.
    """
    fig = plt.figure(figsize=(18, 6))

    # Original image
    ax1 = plt.subplot(1, 3, 1)
    ax1.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))
    ax1.set_title("Original Image")
    ax1.axis('off')

    # Recognized grid
    ax2 = plt.subplot(1, 3, 2)
    ax2.set_title("Recognized Puzzle")
    ax2.axis('off')

    # Draw recognized grid
    for i in range(9):
        for j in range(9):
            digit = recognized_grid[i][j]
            conf = confidence_grid[i][j]

            if digit != 0:
                color = 'blue' if conf > 0.6 else 'red'
                ax2.text(j+0.5, i+0.5, str(digit),
                        ha='center', va='center',
                        fontsize=16, color=color, weight='bold')

    ax2.set_xlim(0, 9)
    ax2.set_ylim(9, 0)
    ax2.set_xticks(range(10))
    ax2.set_yticks(range(10))
    ax2.grid(True)

    # Solved grid
    if solved_grid is not None:
        ax3 = plt.subplot(1, 3, 3)
        ax3.set_title("Solved Puzzle")
        ax3.axis('off')

        for i in range(9):
            for j in range(9):
                digit = solved_grid[i][j]
                # Original digits in blue, solved digits in green
                if recognized_grid[i][j] != 0:
                    color = 'blue'
                    weight = 'bold'
                else:
                    color = 'green'
                    weight = 'normal'

                ax3.text(j+0.5, i+0.5, str(digit),
                        ha='center', va='center',
                        fontsize=16, color=color, weight=weight)

        ax3.set_xlim(0, 9)
        ax3.set_ylim(9, 0)
        ax3.set_xticks(range(10))
        ax3.set_yticks(range(10))
        ax3.grid(True)

    plt.tight_layout()
    plt.show()

print("Visualization functions ready!")

results = {}

for i in range(1, 17):
    filename = f"{i:02d}.jpg"
    print(f"\n{'='*60}")
    print(f"Processing {filename}...")
    print('='*60)

    # Use multi_templates (not digit_templates) and new function
    recognized, solved, confidence, status = process_sudoku_image_updated(filename, multi_templates)

    results[filename] = {
        'recognized': recognized,
        'solved': solved,
        'confidence': confidence,
        'status': status
    }

    print(f"Status: {status}")

    if recognized is not None:
        print("\nRecognized Grid:")
        print(recognized)

        avg_conf = np.mean(confidence[confidence > 0]) if np.any(confidence > 0) else 0
        print(f"Average Confidence: {avg_conf:.2f}")

        if solved is not None:
            print("\nSolved Grid:")
            print(solved)

            # Visualize
            img = cv2.imread(filename)
            visualize_results(img, recognized, solved, confidence)

print("\n" + "="*60)
print("Processing complete!")
print("="*60)